{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Convolutional Variational Autoencoder \n",
    "\n",
    "Using the Conv-VAE package to train a convolutional variational autoencoder on training data collected from the robot. This is put into a notebook, as it needs to be run only once.\n",
    "\n",
    "The result of running this code is the creation of a \"final model\". \n",
    "\n",
    "The encoder portion of this model is the component that can be used for the encoder of the robot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pointer config file: C:\\Users\\lboloni\\.config\\BerryPicker\\mainsettings.yaml\n",
      "Loading machine-specific config file: G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\settings-LotziYoga.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from settings import Config\n",
    "sys.path.append(Config().values[\"conv_vae\"][\"code_dir\"])\n",
    "# print(Config().values)\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# these imports are from the Conv-VAE-Torch package\n",
    "#import data_loader.data_loaders as module_data\n",
    "#import model.loss as module_loss\n",
    "#import model.metric as module_metric\n",
    "#import model.model as module_arch\n",
    "#from parse_config import ConfigParser\n",
    "#from trainer import Trainer\n",
    "#from utils import prepare_device\n",
    "# end of Conv-VAE-Torch imports\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import socket\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "#Fixes PosixPath Error\n",
    "import pathlib\n",
    "\n",
    "# Oh, this hack was fixing something, but for me it is the other way around\n",
    "#temp = pathlib.PosixPath\n",
    "#pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conv_vae import get_config, create_configured_vae_json, train, latest_model, latest_training_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training.\n",
    "\n",
    "The parameters of the training process are set up in the config file.\n",
    "\n",
    "This will give an error about the pandas, which is due to certain adressing mode in the Conv-Vae util.py, which probably will stop working in pandas 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\encoding_conv_vae\\conv-vae-config-default.json\n",
      "{'name': 'VAE_Robot', 'n_gpu': 1, 'arch': {'type': 'VanillaVAE', 'args': {'in_channels': 3, 'latent_dims': 128, 'flow': False}}, 'data_loader': {'type': 'CelebDataLoader', 'args': {'data_dir': 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-training-data\\\\robotonly-uncluttered-2024-10-28', 'batch_size': 64, 'shuffle': True, 'validation_split': 0.2, 'num_workers': 2}}, 'optimizer': {'type': 'Adam', 'args': {'lr': 0.005, 'weight_decay': 0.0, 'amsgrad': True}}, 'loss': 'elbo_loss', 'metrics': [], 'lr_scheduler': {'type': 'StepLR', 'args': {'step_size': 50, 'gamma': 0.1}}, 'trainer': {'epochs': 3, 'save_dir': 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-models\\\\Conv-VAE\\\\', 'save_period': 1, 'verbosity': 2, 'monitor': 'min val_loss', 'early_stop': 10, 'tensorboard': True}}\n",
      "Warning: logging configuration file is not found in logger\\logger_config.json.\n",
      "<parse_config.ConfigParser object at 0x0000015139D635D0>\n",
      "{\n",
      "    \"name\": \"VAE_Robot\",\n",
      "    \"n_gpu\": 1,\n",
      "    \"arch\": {\n",
      "        \"type\": \"VanillaVAE\",\n",
      "        \"args\": {\n",
      "            \"in_channels\": 3,\n",
      "            \"latent_dims\": 128,\n",
      "            \"flow\": false\n",
      "        }\n",
      "    },\n",
      "    \"data_loader\": {\n",
      "        \"type\": \"CelebDataLoader\",\n",
      "        \"args\": {\n",
      "            \"data_dir\": \"c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-training-data\\\\robotonly-uncluttered-2024-10-28\",\n",
      "            \"batch_size\": 64,\n",
      "            \"shuffle\": true,\n",
      "            \"validation_split\": 0.2,\n",
      "            \"num_workers\": 2\n",
      "        }\n",
      "    },\n",
      "    \"optimizer\": {\n",
      "        \"type\": \"Adam\",\n",
      "        \"args\": {\n",
      "            \"lr\": 0.005,\n",
      "            \"weight_decay\": 0.0,\n",
      "            \"amsgrad\": true\n",
      "        }\n",
      "    },\n",
      "    \"loss\": \"elbo_loss\",\n",
      "    \"metrics\": [],\n",
      "    \"lr_scheduler\": {\n",
      "        \"type\": \"StepLR\",\n",
      "        \"args\": {\n",
      "            \"step_size\": 50,\n",
      "            \"gamma\": 0.1\n",
      "        }\n",
      "    },\n",
      "    \"trainer\": {\n",
      "        \"epochs\": 3,\n",
      "        \"save_dir\": \"c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-models\\\\Conv-VAE\\\\\",\n",
      "        \"save_period\": 1,\n",
      "        \"verbosity\": 2,\n",
      "        \"monitor\": \"min val_loss\",\n",
      "        \"early_stop\": 10,\n",
      "        \"tensorboard\": true\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "file = create_configured_vae_json()\n",
    "config = get_config(file)\n",
    "# pretty printing the dict behind the config\n",
    "print(json.dumps(config.config, indent=4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is one way to specify the epochs here, but probably not the best\n",
    "# idea: it should go to the yaml file. \n",
    "# 2024-10-16\n",
    "# I have experienced a mode collapse with the xray training data at 50\n",
    "config[\"trainer\"][\"epochs\"] = 10\n",
    "config[\"trainer\"][\"save_period\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the trainer from scratch for 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:59: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.total[key] += value * n\n",
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:60: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.counts[key] += n\n",
      "C:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:61: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self._data.average[key] = self._data.total[key] / self._data.counts[key]\n",
      "DEBUG:trainer:Train Epoch: 1 [0/596 (0%)] Loss: 159542.750000\n",
      "DEBUG:trainer:Train Epoch: 1 [512/596 (86%)] Loss: 57078.589844\n",
      "INFO:trainer:    epoch          : 1\n",
      "INFO:trainer:    loss           : 82668.6078125\n",
      "WARNING:trainer:Warning: Metric 'val_loss' is not found. Model performance monitoring is disabled.\n",
      "DEBUG:trainer:Train Epoch: 2 [0/596 (0%)] Loss: 55913.796875\n",
      "DEBUG:trainer:Train Epoch: 2 [512/596 (86%)] Loss: 48592.820312\n",
      "INFO:trainer:    epoch          : 2\n",
      "INFO:trainer:    loss           : 55100.7580078125\n",
      "DEBUG:trainer:Train Epoch: 3 [0/596 (0%)] Loss: 51002.660156\n",
      "DEBUG:trainer:Train Epoch: 3 [512/596 (86%)] Loss: 41738.136719\n",
      "INFO:trainer:    epoch          : 3\n",
      "INFO:trainer:    loss           : 41709.23583984375\n",
      "DEBUG:trainer:Train Epoch: 4 [0/596 (0%)] Loss: 40199.335938\n",
      "DEBUG:trainer:Train Epoch: 4 [512/596 (86%)] Loss: 30722.232422\n",
      "INFO:trainer:    epoch          : 4\n",
      "INFO:trainer:    loss           : 32282.85791015625\n",
      "DEBUG:trainer:Train Epoch: 5 [0/596 (0%)] Loss: 30655.812500\n",
      "DEBUG:trainer:Train Epoch: 5 [512/596 (86%)] Loss: 26239.732422\n",
      "INFO:trainer:    epoch          : 5\n",
      "INFO:trainer:    loss           : 26031.287841796875\n",
      "INFO:trainer:Saving checkpoint: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-models\\Conv-VAE\\models\\VAE_Robot\\1101_102107\\checkpoint-epoch5.pth ...\n",
      "DEBUG:trainer:Train Epoch: 6 [0/596 (0%)] Loss: 24417.367188\n",
      "DEBUG:trainer:Train Epoch: 6 [512/596 (86%)] Loss: 18540.884766\n",
      "INFO:trainer:    epoch          : 6\n",
      "INFO:trainer:    loss           : 19674.3669921875\n",
      "DEBUG:trainer:Train Epoch: 7 [0/596 (0%)] Loss: 17423.011719\n",
      "DEBUG:trainer:Train Epoch: 7 [512/596 (86%)] Loss: 11849.772461\n",
      "INFO:trainer:    epoch          : 7\n",
      "INFO:trainer:    loss           : 13002.620288085938\n",
      "DEBUG:trainer:Train Epoch: 8 [0/596 (0%)] Loss: 10685.180664\n",
      "DEBUG:trainer:Train Epoch: 8 [512/596 (86%)] Loss: 7713.112305\n",
      "INFO:trainer:    epoch          : 8\n",
      "INFO:trainer:    loss           : 8370.897314453125\n",
      "DEBUG:trainer:Train Epoch: 9 [0/596 (0%)] Loss: 7400.426270\n",
      "DEBUG:trainer:Train Epoch: 9 [512/596 (86%)] Loss: 7198.545898\n",
      "INFO:trainer:    epoch          : 9\n",
      "INFO:trainer:    loss           : 6672.102392578125\n",
      "DEBUG:trainer:Train Epoch: 10 [0/596 (0%)] Loss: 7466.994141\n",
      "DEBUG:trainer:Train Epoch: 10 [512/596 (86%)] Loss: 6337.561035\n",
      "INFO:trainer:    epoch          : 10\n",
      "INFO:trainer:    loss           : 6833.695166015625\n",
      "INFO:trainer:Saving checkpoint: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-models\\Conv-VAE\\models\\VAE_Robot\\1101_102107\\checkpoint-epoch10.pth ...\n",
      "DEBUG:trainer:Train Epoch: 11 [0/596 (0%)] Loss: 8457.503906\n",
      "DEBUG:trainer:Train Epoch: 11 [512/596 (86%)] Loss: 21490.699219\n",
      "INFO:trainer:    epoch          : 11\n",
      "INFO:trainer:    loss           : 18318.568115234375\n",
      "DEBUG:trainer:Train Epoch: 12 [0/596 (0%)] Loss: 17348.824219\n",
      "DEBUG:trainer:Train Epoch: 12 [512/596 (86%)] Loss: 7471.908691\n",
      "INFO:trainer:    epoch          : 12\n",
      "INFO:trainer:    loss           : 10576.904614257812\n",
      "DEBUG:trainer:Train Epoch: 13 [0/596 (0%)] Loss: 10106.291016\n",
      "DEBUG:trainer:Train Epoch: 13 [512/596 (86%)] Loss: 6032.648926\n",
      "INFO:trainer:    epoch          : 13\n",
      "INFO:trainer:    loss           : 6982.850415039063\n",
      "DEBUG:trainer:Train Epoch: 14 [0/596 (0%)] Loss: 6092.824707\n",
      "DEBUG:trainer:Train Epoch: 14 [512/596 (86%)] Loss: 5113.918457\n",
      "INFO:trainer:    epoch          : 14\n",
      "INFO:trainer:    loss           : 5002.690246582031\n",
      "DEBUG:trainer:Train Epoch: 15 [0/596 (0%)] Loss: 5495.281250\n",
      "DEBUG:trainer:Train Epoch: 15 [512/596 (86%)] Loss: 5038.221191\n",
      "INFO:trainer:    epoch          : 15\n",
      "INFO:trainer:    loss           : 4571.417041015625\n",
      "INFO:trainer:Saving checkpoint: c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-models\\Conv-VAE\\models\\VAE_Robot\\1101_102107\\checkpoint-epoch15.pth ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# actually run the training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning the trainer from scratch for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\encoding_conv_vae\\conv_vae.py:98\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     88\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39minit_obj(\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_scheduler\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler, optimizer)\n\u001b[0;32m     91\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model, criterion, optimizer,\n\u001b[0;32m     92\u001b[0m                   config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m     93\u001b[0m                   device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     94\u001b[0m                   data_loader\u001b[38;5;241m=\u001b[39mdata_loader,\n\u001b[0;32m     95\u001b[0m                   valid_data_loader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     96\u001b[0m                   lr_scheduler\u001b[38;5;241m=\u001b[39mlr_scheduler)\n\u001b[1;32m---> 98\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\base\\base_trainer.py:66\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m not_improved_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 66\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# save logged informations into log dict\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     log \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch}\n",
      "File \u001b[1;32m~\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\trainer\\trainer.py:50\u001b[0m, in \u001b[0;36mTrainer._train_epoch\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_metrics\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loader):\n\u001b[0;32m     51\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:440\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_VirtualEnvironments\\Robot\\Robot-venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1038\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1031\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1038\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 94\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# actually run the training\n",
    "print(f'Running the trainer from scratch for {config[\"trainer\"][\"epochs\"]}')\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest training run is 1101_102107 in directory\n",
      "c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-models\\Conv-VAE\\\n"
     ]
    }
   ],
   "source": [
    "# FIXME: this one returns models, but it should return what was under it.\n",
    "\n",
    "model_path = pathlib.Path(config[\"trainer\"][\"save_dir\"], \"models\", config[\"name\"])\n",
    "\n",
    "training_run = latest_training_run(model_path)\n",
    "print(f'The latest training run is {training_run} in directory\\n{config[\"trainer\"][\"save_dir\"]}')\n",
    "\n",
    "print = latest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
