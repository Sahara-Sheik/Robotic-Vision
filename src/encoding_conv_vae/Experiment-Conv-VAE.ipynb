{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactively validate a Convolutional Variational Autoencoder\n",
    "\n",
    "The code in this nodebook is loading a pre-trained model and experiment with the encoder and decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pointer config file: /home/lboloni/.config/BerryPicker/mainsettings.yaml\n",
      "Loading machine-specific config file: /home/lboloni/Insync/lotzi.boloni@gmail.com/Google Drive/LotziStudy/Code/PackageTracking/BerryPicker/settings/settings-tredy2.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# adding the Julian-8897-Conv-VAE-PyTorch into the path\n",
    "from settings import Config\n",
    "sys.path.append(Config().values[\"conv_vae\"][\"code_dir\"])\n",
    "# from encoding_conv_vae.conv_vae import latest_json_and_model\n",
    "\n",
    "from sensorprocessing import sp_conv_vae\n",
    "from sensorprocessing import sp_helper\n",
    "\n",
    "from helper import ui_choose_task, ui_choose_demo\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Oh, this hack was fixing something, but for me it is the other way around\n",
    "#temp = pathlib.PosixPath\n",
    "#pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing experiment system dependent config file /home/lboloni/Insync/lotzi.boloni@gmail.com/Google Drive/LotziStudy/Code/PackageTracking/BerryPicker/settings/experiment-config/Tredy2/conv_vae/vae_00_sysdep.yaml, that is ok, proceeding.\n",
      "Configuration for experiment: conv_vae/vae_00 successfully loaded\n",
      "/home/lboloni/Documents/Hackingwork/__Temporary/BerryPicker-experiments/conv_vae/vae_00/models/VAE_Robot/1220_172927/config.json\n",
      "/home/lboloni/Documents/Hackingwork/__Temporary/BerryPicker-experiments/conv_vae/vae_00/models/VAE_Robot/1220_172927/checkpoint-epoch100.pth\n"
     ]
    }
   ],
   "source": [
    "# pick the latest\n",
    "# conv_vae_jsonfile, resume_model_pthfile = latest_json_and_model()\n",
    "run = \"vae_00\"\n",
    "exp = Config().get_experiment(\"conv_vae\", run)\n",
    "model_subdir = Path(exp[\"data_dir\"], exp[\"model_dir\"], \"models\", exp[\"model_name\"], exp[\"model_subdir\"])\n",
    "conv_vae_jsonfile = Path(model_subdir, \"config.json\")\n",
    "resume_model_pthfile = Path(model_subdir, exp[\"model_checkpoint\"])\n",
    "print(conv_vae_jsonfile)\n",
    "print(resume_model_pthfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/lboloni/Documents/Hackingwork/__Temporary/BerryPicker-experiments/conv_vae/vae_00/models/VAE_Robot/1220_172927/config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sp \u001b[38;5;241m=\u001b[39m \u001b[43msp_conv_vae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConvVaeSensorProcessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_vae_jsonfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume_model_pthfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(sp\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sp\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencoder)\n",
      "File \u001b[0;32m~/Documents/Hackingwork/_Checkouts/BerryPicker/BerryPicker/src/encoding_conv_vae/../sensorprocessing/sp_conv_vae.py:49\u001b[0m, in \u001b[0;36mConvVaeSensorProcessing.__init__\u001b[0;34m(self, conv_vae_jsonfile, resume_model_pthfile)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_vae_jsonfile \u001b[38;5;241m=\u001b[39m conv_vae_jsonfile\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_model_pthfile \u001b[38;5;241m=\u001b[39m resume_model_pthfile\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_conv_vae_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_vae_jsonfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume_model_pthfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# build model architecture\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae_config\u001b[38;5;241m.\u001b[39minit_obj(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124march\u001b[39m\u001b[38;5;124m'\u001b[39m, module_arch)\n",
      "File \u001b[0;32m~/Documents/Hackingwork/_Checkouts/BerryPicker/BerryPicker/src/encoding_conv_vae/../encoding_conv_vae/conv_vae.py:210\u001b[0m, in \u001b[0;36mget_conv_vae_config\u001b[0;34m(jsonfile, resume_model, inference_only)\u001b[0m\n\u001b[1;32m    208\u001b[0m savedargv \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv\n\u001b[1;32m    209\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m--> 210\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mConfigParser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m savedargv\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# print(json.dumps(config.config, indent=4))\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# THIS was an attempt to fix some kind of weird bug where an empty \u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# directory was created... it is not needed on 2024.11.17???\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# if it is inference only, remove the superfluously created directories.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Hackingwork/_Checkouts/Julian-8897-Conv-VAE-PyTorch/Conv-VAE-PyTorch/parse_config.py:71\u001b[0m, in \u001b[0;36mConfigParser.from_args\u001b[0;34m(cls, args, options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     resume \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     cfg_fname \u001b[38;5;241m=\u001b[39m Path(args\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m---> 71\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_fname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;129;01mand\u001b[39;00m resume:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# update new config for fine-tuning\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     config\u001b[38;5;241m.\u001b[39mupdate(read_json(args\u001b[38;5;241m.\u001b[39mconfig))\n",
      "File \u001b[0;32m~/Documents/Hackingwork/_Checkouts/Julian-8897-Conv-VAE-PyTorch/Conv-VAE-PyTorch/utils/util.py:16\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_json\u001b[39m(fname):\n\u001b[1;32m     15\u001b[0m     fname \u001b[38;5;241m=\u001b[39m Path(fname)\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(handle, object_hook\u001b[38;5;241m=\u001b[39mOrderedDict)\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1119\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1118\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/lboloni/Documents/Hackingwork/__Temporary/BerryPicker-experiments/conv_vae/vae_00/models/VAE_Robot/1220_172927/config.json'"
     ]
    }
   ],
   "source": [
    "\n",
    "sp = sp_conv_vae.ConvVaeSensorProcessing(conv_vae_jsonfile, resume_model_pthfile)\n",
    "print(sp.model)\n",
    "print(sp.model.encoder)\n",
    "print(f\"latent_dim {sp.model.latent_dim}\")\n",
    "# print(model.hidden_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass one picture through the complete autoencoder\n",
    "\n",
    "Pass one specific picture through the complete autoencoder. Compare the input and the output. This is basically trying out whether the VAE had captured the picture sufficiently.\n",
    "\n",
    "This code also is intended as a sample of how to use the pre-trained model, how to feed it new data without the training code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picture_name = '../../localdata/img/Rafael.jpg'\n",
    "# picture_name = '../../localdata/img/indian-man.jpeg'\n",
    "# picture_name = '../../localdata/img/00029_dev2.jpg'\n",
    "\n",
    "# Choose a random image from the training data. \n",
    "\n",
    "directory = pathlib.Path(Config().values[\"conv_vae\"][\"training_data_dir\"], \"Images\")\n",
    "print(directory)\n",
    "files = list(directory.glob('*.jpg'))\n",
    "picture_name = pathlib.Path(directory, files[11])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the sensor processing object works"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "val = sp.process_file(picture_name)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_VAE(sp, picture_name, axoriginal, axreconstr):\n",
    "    \"\"\"Visualize the performance of the reconstruction of a VAE sensorprocessing object. Show the original and the reconstruction in fields of a picture.\"\"\"\n",
    "    transform = sp_helper.get_transform_to_robot()\n",
    "    input, image = sp_helper.load_picturefile_to_tensor(picture_name, transform)\n",
    "    # Running the input on the output\n",
    "    output, mu, logvar = sp.model(input)\n",
    "    # Output: the visual reconstruction\n",
    "    output_for_pic = output[0].cpu().permute(1, 2, 0).detach().numpy()\n",
    "    # Showing the input and the reconstruction    \n",
    "    axoriginal.imshow(image)\n",
    "    axreconstr.imshow(output_for_pic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement me: choose a random set of images from a task\n",
    "\n",
    "_, task_dir = ui_choose_task(offer_task_creation=True)\n",
    "print(task_dir)\n",
    "demo_dir = ui_choose_demo(task_dir)\n",
    "# FIXME: need to choose the demonstration\n",
    "jpg_files = list(demo_dir.glob(\"*.jpg\"))\n",
    "n = 6\n",
    "randomjpg = random.sample(jpg_files, n)\n",
    "fig, axs = plt.subplots(2, n, figsize=(10, 5))\n",
    "for i in range(n):\n",
    "    visualize_VAE(sp, randomjpg[i], axs[0,i], axs[1,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Try to do a decoding from the same mu\n",
    "z2 = sp.model.reparameterize(mu, logvar)\n",
    "\n",
    "for i in range(Config().values[\"robot\"][\"latent_encoding_size\"]):\n",
    "    z2[0][i] = z2[0][i] + 0.1\n",
    "\n",
    "#z2[0][1] = 2.0\n",
    "#z2[0][3] = 2.0\n",
    "output2 = sp.model.decode(z2)\n",
    "output_for_pic2 = output2[0].cpu().permute(1, 2, 0).detach().numpy()\n",
    "\n",
    "# initial and new\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(output_for_pic)\n",
    "axs[1].imshow(output_for_pic2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random samples from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# z2 = model.reparameterize(mu, logvar)\n",
    "# initial and new\n",
    "fig, axs = plt.subplots(5, 5, figsize=(10, 10))\n",
    "for x in range(0, 5):\n",
    "    for y in range(0, 5):\n",
    "            z2 = sp.model.reparameterize(mu, logvar)\n",
    "            for i in range(Config().values[\"robot\"][\"latent_encoding_size\"]):\n",
    "                z2[0][i] += random.uniform(-0.5, 0.5)\n",
    "            output2 = sp.model.decode(z2)\n",
    "            output_for_pic2 = output2[0].cpu().permute(1, 2, 0).detach().numpy()\n",
    "            axs[x][y].imshow(output_for_pic2)\n",
    "#axs[0].imshow(output_for_pic)\n",
    "#axs[1].imshow(output_for_pic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
