{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sensor processing model using a Convolutional Variational Autoencoder \n",
    "\n",
    "Using the Julian-8897-Conv-VAE-PyTorch implementation to train a sensor processing model based on convolutional variational autoencoder. \n",
    "\n",
    "The parameters of the training are described by an experiment run of type \"sensorprocessing_conv_vae\". The result of runing the code in this notebook is the model files that are stored in the experiment directory. \n",
    "\n",
    "As the model files will have unpredictable date-time dependent names, after running a satisfactory model, the mode name and directory will need to be copied to the experiment/run yaml file, in the model_subdir and model_checkpoint fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from settings import Config\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "import shutil\n",
    "\n",
    "# adding the Julian-8897-Conv-VAE-PyTorch into the path\n",
    "sys.path.append(Config()[\"conv_vae\"][\"code_dir\"])\n",
    "\n",
    "# At some point in the development, this hack was necessary for some reason. \n",
    "# It seems that as of Feb 2025, the code runs on Windows and Linux without it.\n",
    "#temp = pathlib.PosixPath\n",
    "#pathlib.PosixPath = pathlib.WindowsPath\n",
    "\n",
    "from conv_vae import get_conv_vae_config, create_configured_vae_json, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it is set to true, no actual copying will be done\n",
    "dry_run = False\n",
    "\n",
    "# Specify and load the experiment\n",
    "experiment = \"sensorprocessing_conv_vae\"\n",
    "run = \"proprio_128\" \n",
    "exp = Config().get_experiment(experiment, run)\n",
    "pprint(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training data for the Conv-VAE\n",
    "\n",
    "We collect the training data for the Conv-VAE by gathering all the pictures from all the demonstrations of a specific task. One can select the pictures by creating a specific task, and copy there all the relevant demonstrations. \n",
    "\n",
    "The collected pictures are put in a newly created training directory for the run:\n",
    "\n",
    "```\n",
    "$experiment\\vae-training-data\\Images\\*.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_images_to_training_dir(taskname, training_image_dir):\n",
    "    \"\"\"Copy all the images from a specific task into the training image dir.\"\"\"\n",
    "    task_dir = pathlib.Path(demos_dir, taskname)\n",
    "    # _, task_dir = ui_choose_task(offer_task_creation=True)\n",
    "\n",
    "    for demo in task_dir.iterdir():\n",
    "        if not demo.is_dir(): continue\n",
    "        for item in demo.iterdir():\n",
    "            if item.suffix != \".jpg\": continue\n",
    "            name = f\"{demo.name}_{item.stem}.jpg\"\n",
    "            destination = pathlib.Path(training_image_dir, name)\n",
    "            print(f\"copy {item} to \\n{destination}\")\n",
    "            if not dry_run:\n",
    "                shutil.copyfile(item, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demos_top = pathlib.Path(Config()[\"demos\"][\"directory\"])\n",
    "demos_dir = pathlib.Path(demos_top, \"demos\")\n",
    "\n",
    "subdir_count = sum(1 for item in demos_dir.iterdir() if item.is_dir())\n",
    "print(f\"Number of demo directories: {subdir_count}\")\n",
    "\n",
    "# Deciding on the location of the training data\n",
    "training_data_dir = pathlib.Path(exp[\"data_dir\"], exp[\"training_data_dir\"])\n",
    "# training_data_dir = pathlib.Path(Config()[\"conv_vae\"][\"training_data_dir\"])\n",
    "training_image_dir = pathlib.Path(training_data_dir, \"Images\")\n",
    "training_image_dir.mkdir(exist_ok = False, parents=True)\n",
    "\n",
    "print(f\"Training data dir={training_image_dir}\")\n",
    "\n",
    "# Define a set of common image file extensions\n",
    "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\", \".tiff\", \".webp\"}\n",
    "# Count the image files\n",
    "image_count = sum(1 for item in training_image_dir.iterdir() if item.suffix.lower() in image_extensions and item.is_file())\n",
    "\n",
    "print(f\"Number of image files in training dir: {image_count}\")\n",
    "\n",
    "if image_count == 0:\n",
    "    taskname = exp['training_task']\n",
    "    copy_images_to_training_dir(\n",
    "        taskname = taskname, training_image_dir=training_image_dir)\n",
    "else:\n",
    "    print(\"There are already images in training image dir {training_image_dir}. Do not repeat the copying.\")            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the training\n",
    "\n",
    "Actually run the training. This is done by creating the json-based configuration file of the Conv-VAE library with the parameters specified in the library. Then we call the code of the library to perform the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vae configuration, based on the experiment\n",
    "file = create_configured_vae_json(exp)\n",
    "print(file)\n",
    "vae_config = get_conv_vae_config(file)\n",
    "\n",
    "# actually run the training\n",
    "print(f'Running the trainer from scratch for {vae_config[\"trainer\"][\"epochs\"]}')\n",
    "trainer = train(vae_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the metrics recorded\n",
    "# they are of utils/util.py / MetricTracker which has a pandas dataframe as data\n",
    "print(trainer.train_metrics)\n",
    "print(trainer.valid_metrics)\n",
    "# \n",
    "trainer.train_metrics._data\n",
    "# trainer.valid_metrics._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important__ After the training finished, in order to use the resulting system, one need to edit the run file (eg: vae_01.yaml) and enter into it the location of the checkpoint. This is the content printed by the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"model_subdir: '{trainer.checkpoint_dir.name}'\")\n",
    "print(f\"model_checkpoint: 'checkpoint-epoch{trainer.epochs}.pth'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BerryPicker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
