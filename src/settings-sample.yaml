# the location where the system dependent experiment config files are
"experiment_system_dependent_dir": '/the/dir/where/your/machine/dependent/experiment/configs/go'
# the location where the experiment data is put
# the experiments's specific data will be _/className/runName
"experiment_data": '/the/dir/where/your/experiment/data/and/models/go'

robot:
  
  # The USB port where the AL5D robot is connected on this particular computer.
  # alternatives: linux: /dev/ttyUSB0, /dev/ttyUSB1
  usb_port: "/dev/ttyUSB0"

  # The camera numbers which should be used for the robot, as a list
  # Typically 0 is the webcam of the computer, other ones in the order they are connected
  active_camera_list: [2]

  ## Size of the latent encoding
  ## FIXME: in the case of the Conv-VAE, this number must be the same as the one
  ## in the conf-robot-machinename.json, latent_dims
  latent_encoding_size: 128


  # Action space size 
  action_space_size: 6

  # Image size: the size to which the images need to be reduced 
  # before introduced into the vision system. 
  # CONV-VAE cannot handle anything but 64 in its current configuration
  image_size: [64, 64]
  
  # The image size at which we are saving at demonstrations. It is larger 
  # than the one used by conv_vae to allow for 
  saved_image_size: [256, 256]

demos:

  # Data directory for demonstrations. This is where demonstrations are saved, or loaded from in the case of replay
  directory: "/path/to/the/directory/of/demonstrations"

training:
  # Data directory for training data. This is where the training data is kept and organized 
  directory: "."

conv_vae:
  # Directory for the checkout of the CONV_VAE project 
  # https://github.com/julian-8897/Conv-VAE-PyTorch
  code_dir: 'path/to/checkout/Julian-8897-Conv-VAE-PyTorch/Conv-VAE-PyTorch'
  # The json file which is going to be used as the starting point
  json_template: '/path/to/the/json/file'
  # The name of the model that is used in the JSON file 
  model_name: 'VAE_Robot'
  model_dir: '/path/to/where/to/store/the/model/VisionBasedRobotManipulator-models/Conv-VAE/'
  model_file: 'path/to/checkpoint/to/use/checkpoint-epoch20.pth'
  training_data_dir: 'path/to/training/data/dir/vae-training-data'   