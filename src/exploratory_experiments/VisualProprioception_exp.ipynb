{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual proprioception experiments\n",
    "\n",
    "Experiments investigating various configurations for the visual proprioception of the robot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pointer config file: C:\\Users\\lboloni\\.config\\BerryPicker\\mainsettings.yaml\n",
      "Loading machine-specific config file: G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\settings-LotziYoga.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from settings import Config\n",
    "\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from behavior_cloning.demo_to_trainingdata import BCDemonstration\n",
    "from sensorprocessing import sp_conv_vae, sp_cnn\n",
    "from robot.al5d_position_controller import RobotPosition\n",
    "\n",
    "from visual_proprioception.visproprio_helper import load_demonstrations_as_proprioception_training\n",
    "from visual_proprioception.visproprio_models import VisProprio_SimpleMLPRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing experiment system dependent config file G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\visual_proprioception\\vae_mlp_01_sysdep.yaml, that is ok, proceeding.\n",
      "Configuration for experiment: visual_proprioception/vae_mlp_01 successfully loaded\n",
      "{'data_dir': WindowsPath('c:/Users/lboloni/Documents/Code/_TempData/BerryPicker-experiments/visual_proprioception/vae_mlp_01'),\n",
      " 'encoding_size': 512,\n",
      " 'epochs': 3000,\n",
      " 'group_name': 'visual_proprioception',\n",
      " 'output_size': 6,\n",
      " 'proprioception_input_file': 'train_inputs.pt',\n",
      " 'proprioception_mlp_model_file': 'proprioception_mlp.pth',\n",
      " 'proprioception_target_file': 'train_targets.pt',\n",
      " 'proprioception_test_input_file': 'test_inputs.pt',\n",
      " 'proprioception_test_target_file': 'test_targets.pt',\n",
      " 'proprioception_testing_task': 'random-uncluttered-test',\n",
      " 'proprioception_training_task': 'random-uncluttered',\n",
      " 'regressor_hidden_size_1': 64,\n",
      " 'regressor_hidden_size_2': 64,\n",
      " 'run_name': 'vae_mlp_01',\n",
      " 'sensor_processing': 'vae',\n",
      " 'sp_experiment': 'conv_vae',\n",
      " 'sp_run': 'vae_01'}\n",
      "Missing experiment system dependent config file G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\conv_vae\\vae_01_sysdep.yaml, that is ok, proceeding.\n",
      "Configuration for experiment: conv_vae/vae_01 successfully loaded\n",
      "Missing experiment system dependent config file G:\\My Drive\\LotziStudy\\Code\\PackageTracking\\BerryPicker\\settings\\experiment-config\\LotziYoga\\conv_vae\\vae_01_sysdep.yaml, that is ok, proceeding.\n",
      "Configuration for experiment: conv_vae/vae_01 successfully loaded\n",
      "c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\conv_vae\\vae_01\\models\\models\\VAE_Robot\\1222_150723\\config.json\n",
      "c:\\Users\\lboloni\\Documents\\Code\\_TempData\\BerryPicker-experiments\\conv_vae\\vae_01\\models\\models\\VAE_Robot\\1222_150723\\checkpoint-epoch100.pth\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-experiments\\\\conv_vae\\\\vae_01\\\\models\\\\models\\\\VAE_Robot\\\\1222_150723\\\\config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor_processing\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      7\u001b[0m     spexp \u001b[38;5;241m=\u001b[39m Config()\u001b[38;5;241m.\u001b[39mget_experiment(\n\u001b[0;32m      8\u001b[0m         exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msp_experiment\u001b[39m\u001b[38;5;124m'\u001b[39m], exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msp_run\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m     sp \u001b[38;5;241m=\u001b[39m \u001b[43msp_conv_vae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sp_of_conv_vae_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msp_run\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msensor_processing\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg19\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     11\u001b[0m     spexp \u001b[38;5;241m=\u001b[39m Config()\u001b[38;5;241m.\u001b[39mget_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msp_cnn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg19_orig\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\exploratory_experiments\\..\\sensorprocessing\\sp_conv_vae.py:58\u001b[0m, in \u001b[0;36mget_sp_of_conv_vae_experiment\u001b[1;34m(run)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExists!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(resume_model_pthfile)\n\u001b[1;32m---> 58\u001b[0m sp \u001b[38;5;241m=\u001b[39m \u001b[43mConvVaeSensorProcessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_vae_jsonfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume_model_pthfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(sp\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(sp\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencoder)\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\exploratory_experiments\\..\\sensorprocessing\\sp_conv_vae.py:72\u001b[0m, in \u001b[0;36mConvVaeSensorProcessing.__init__\u001b[1;34m(self, conv_vae_jsonfile, resume_model_pthfile)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_vae_jsonfile \u001b[38;5;241m=\u001b[39m conv_vae_jsonfile\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_model_pthfile \u001b[38;5;241m=\u001b[39m resume_model_pthfile\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_conv_vae_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_vae_jsonfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresume_model_pthfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# build model architecture\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvae_config\u001b[38;5;241m.\u001b[39minit_obj(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124march\u001b[39m\u001b[38;5;124m'\u001b[39m, module_arch)\n",
      "File \u001b[1;32mc:\\Users\\lboloni\\Documents\\Code\\_Checkouts\\BerryPicker\\src\\exploratory_experiments\\..\\encoding_conv_vae\\conv_vae.py:215\u001b[0m, in \u001b[0;36mget_conv_vae_config\u001b[1;34m(jsonfile, resume_model, inference_only)\u001b[0m\n\u001b[0;32m    213\u001b[0m savedargv \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv\n\u001b[0;32m    214\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m--> 215\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mConfigParser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m sys\u001b[38;5;241m.\u001b[39margv \u001b[38;5;241m=\u001b[39m savedargv\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# print(json.dumps(config.config, indent=4))\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# THIS was an attempt to fix some kind of weird bug where an empty \u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# directory was created... it is not needed on 2024.11.17???\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# if it is inference only, remove the superfluously created directories.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\parse_config.py:71\u001b[0m, in \u001b[0;36mConfigParser.from_args\u001b[1;34m(cls, args, options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     resume \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     cfg_fname \u001b[38;5;241m=\u001b[39m Path(args\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[1;32m---> 71\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_fname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;129;01mand\u001b[39;00m resume:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# update new config for fine-tuning\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     config\u001b[38;5;241m.\u001b[39mupdate(read_json(args\u001b[38;5;241m.\u001b[39mconfig))\n",
      "File \u001b[1;32m~\\Documents\\Code\\_Checkouts\\Conv-VAE-PyTorch\\utils\\util.py:16\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(fname)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_json\u001b[39m(fname):\n\u001b[0;32m     15\u001b[0m     fname \u001b[38;5;241m=\u001b[39m Path(fname)\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(handle, object_hook\u001b[38;5;241m=\u001b[39mOrderedDict)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:1044\u001b[0m, in \u001b[0;36mPath.open\u001b[1;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1043\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m-> 1044\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m, mode, buffering, encoding, errors, newline)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\lboloni\\\\Documents\\\\Code\\\\_TempData\\\\BerryPicker-experiments\\\\conv_vae\\\\vae_01\\\\models\\\\models\\\\VAE_Robot\\\\1222_150723\\\\config.json'"
     ]
    }
   ],
   "source": [
    "# run = \"vae_mlp_00\"\n",
    "run = \"vae_mlp_01\"\n",
    "exp = Config().get_experiment(\"visual_proprioception\", run)\n",
    "pprint(exp)\n",
    "\n",
    "if exp[\"sensor_processing\"] == \"vae\":\n",
    "    spexp = Config().get_experiment(\n",
    "        exp['sp_experiment'], exp['sp_run'])\n",
    "    sp = sp_conv_vae.get_sp_of_conv_vae_experiment(exp['sp_run'])\n",
    "if exp['sensor_processing'] == \"vgg19\":\n",
    "    spexp = Config().get_experiment(\"sp_cnn\", \"vgg19_orig\")\n",
    "    sp = sp_cnn.VGG19SensorProcessing(spexp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = exp[\"proprioception_training_task\"]\n",
    "proprioception_input_file = pathlib.Path(\n",
    "    exp[\"data_dir\"], exp[\"proprioception_input_file\"])\n",
    "proprioception_target_file = pathlib.Path(\n",
    "    exp[\"data_dir\"], exp[\"proprioception_target_file\"])\n",
    "tr = load_demonstrations_as_proprioception_training(\n",
    "    sp, task, proprioception_input_file, proprioception_target_file)\n",
    "inputs_training = tr[\"inputs_training\"]\n",
    "targets_training = tr[\"targets_training\"]\n",
    "inputs_validation = tr[\"inputs_validation\"]\n",
    "targets_validation = tr[\"targets_validation\"]\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "#input_size = inputs_training.size(1)\n",
    "#hidden_size = 64\n",
    "#output_size = targets_training.size(1)\n",
    "\n",
    "\n",
    "# print(input_size)\n",
    "# print(output_size)\n",
    "\n",
    "model = VisProprio_SimpleMLPRegression(exp)\n",
    "# criterion = nn.MSELoss()\n",
    "# Experiment: would this be better???\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for batching\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(inputs_training, targets_training)\n",
    "test_dataset = TensorDataset(inputs_validation, targets_validation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_proprioception_model(modelfile, epochs=20):\n",
    "    \"\"\"Trains and saves the proprioception model\n",
    "    FIXME: must have parameters etc to investigate alternative models. \n",
    "    \"\"\"\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            # Forward pass\n",
    "            predictions = model(batch_X)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            predictions = model(batch_X)\n",
    "            loss = criterion(predictions, batch_y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    torch.save(model.state_dict(), modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelfile = pathlib.Path(Config()[\"explorations\"][\"proprioception_mlp_model_file\"])\n",
    "modelfile = pathlib.Path(exp[\"data_dir\"], \n",
    "                         exp[\"proprioception_mlp_model_file\"])\n",
    "epochs = exp[\"epochs\"]\n",
    "if modelfile.exists():\n",
    "    model.load_state_dict(torch.load(modelfile))\n",
    "else:\n",
    "    train_and_save_proprioception_model(modelfile, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the reloaded model works\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        predictions = model(batch_X)\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "torch.save(model.state_dict(), modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the proprioception\n",
    "Run the model with the original input.\n",
    "FIXME: here we need to make a different set of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = []\n",
    "\n",
    "task = exp[\"proprioception_testing_task\"]\n",
    "proprioception_input_file = pathlib.Path(\n",
    "    exp[\"data_dir\"], exp[\"proprioception_test_input_file\"])\n",
    "proprioception_target_file = pathlib.Path(\n",
    "    exp[\"data_dir\"], exp[\"proprioception_test_target_file\"])\n",
    "tr2 = load_demonstrations_as_proprioception_training(\n",
    "    sp, task, proprioception_input_file, proprioception_target_file)\n",
    "\n",
    "inputs = tr2[\"inputs\"] # these are actually tensors\n",
    "targets = tr2[\"targets\"]\n",
    "no_from = 0\n",
    "no_to = inputs.shape[0]\n",
    "ypred = []\n",
    "y = []\n",
    "t = []\n",
    "with torch.no_grad():\n",
    "    for i in range(no_from, no_to):\n",
    "        x = inputs[i]\n",
    "        predictions = model(torch.unsqueeze(x, dim=0))\n",
    "        # append the data \n",
    "        t.append(i)\n",
    "        y.append(targets[i].numpy())\n",
    "        ypred.append(predictions[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = np.array(ypred)\n",
    "y = np.array(y)\n",
    "t = np.array(t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a graph with the six degrees of freedom, predicted and real value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3, constrained_layout=True)\n",
    "titles = [\"height\",\"distance\", \"heading\", \"wrist_angle\", \"wrist_rotation\", \"gripper\"]\n",
    "for i in range(Config()[\"robot\"][\"action_space_size\"]):\n",
    "    ax = axs[i//3, i%3] \n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.plot(t, y[:,i], label=\"y\")\n",
    "    ax.plot(t, ypred[:,i], label=\"yhat\")\n",
    "    ax.legend()\n",
    "    ax.set_title(titles[i])\n",
    "\n",
    "graphfilename = pathlib.Path(exp[\"data_dir\"], \"proprio_error.pdf\")\n",
    "plt.savefig(graphfilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_MAX = {\"height\": 5.0, \"distance\": 10.0, \"heading\": 90.0, \n",
    "               \"wrist_angle\": 90.0, \"wrist_rotation\": 75.0 + 90.0, \n",
    "               \"gripper\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fld in enumerate(POS_MAX):\n",
    "    print(i, fld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Robot-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
