{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an LSTM based controller \n",
    "\n",
    "Train and save an LSTM-based controller. It contains:\n",
    "* Code for loading and pre-processing the training data. \n",
    "* Training an LSTM with specific parameters and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pointer config file: /home/ssheikholeslami/.config/BerryPicker/mainsettings.yaml\n",
      "Loading machine-specific config file: /home/ssheikholeslami/SaharaBerryPickerData/settings-sahara.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from settings import Config\n",
    "\n",
    "import pathlib\n",
    "#from pprint import pformat\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "from sensorprocessing import sp_conv_vae\n",
    "from demo_to_trainingdata import create_RNN_training_sequence_xy, BCDemonstration\n",
    "from bc_LSTM import LSTMXYPredictor, LSTMResidualController\n",
    "from robot.al5d_position_controller import RobotPosition\n",
    "\n",
    "from tensorboardX import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and validation data\n",
    "Create training and validation data from all the demonstrations of a certain task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_bc_training_and_validation(task):\n",
    "    conv_vae_jsonfile = pathlib.Path(Config()[\"controller\"][\"vae_json\"])\n",
    "    conv_vae_model_pthfile = pathlib.Path(Config()[\"controller\"][\"vae_model\"])\n",
    "\n",
    "\n",
    "    sp = sp_conv_vae.ConvVaeSensorProcessing(conv_vae_jsonfile,\n",
    "                                            conv_vae_model_pthfile)\n",
    "\n",
    "    demos_dir = pathlib.Path(Config()[\"demos\"][\"directory\"])\n",
    "    task_dir = pathlib.Path(demos_dir, \"demos\", task)\n",
    "\n",
    "    inputlist = []\n",
    "    targetlist = []\n",
    "\n",
    "    for demo_dir in task_dir.iterdir():\n",
    "        if not demo_dir.is_dir():\n",
    "            pass\n",
    "        bcd = BCDemonstration(demo_dir, sensorprocessor=sp)\n",
    "        print(bcd)\n",
    "        z, a = bcd.read_z_a()\n",
    "        # normalize the actions\n",
    "        print(z.shape)\n",
    "        print(a.shape)\n",
    "        anorm = np.zeros(a.shape, np.float32)\n",
    "        for i in range(a.shape[0]):\n",
    "            rp = RobotPosition.from_vector(a[i])\n",
    "            anorm[i,:] = rp.to_normalized_vector()\n",
    "\n",
    "        # FIXME the repeated name for inputs and targets\n",
    "        inputs, targets = create_RNN_training_sequence_xy(z, anorm, sequence_length=10)\n",
    "        inputlist.append(inputs)\n",
    "        targetlist.append(targets)\n",
    "\n",
    "    inputs = torch.cat(inputlist)\n",
    "    targets = torch.cat(targetlist)\n",
    "\n",
    "    # Separate the training and validation data.\n",
    "    # We will be shuffling the demonstrations\n",
    "    rows = torch.randperm(inputs.size(0))\n",
    "    shuffled_inputs = inputs[rows]\n",
    "    shuffled_targets = targets[rows]\n",
    "\n",
    "    training_size = int( inputs.size(0) * 0.67 )\n",
    "    inputs_training = shuffled_inputs[1:training_size]\n",
    "    targets_training = shuffled_targets[1:training_size]\n",
    "\n",
    "    inputs_validation = shuffled_inputs[training_size:]\n",
    "    targets_validation = shuffled_targets[training_size:]\n",
    "    return inputs_training, targets_training, input_validation, targets_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_behavior_cloning(model, criterion, inputs_validation, targets_validation):\n",
    "    \"\"\"Calculates the validation error for the behavior cloning model using pairs of input strings (of the specific length) and single output target strings.\n",
    "    The model is reset before each of the strings (i.e. state is not transferred)\n",
    "    model: an LSTM or similar model that can consume a sequence of inputs\n",
    "    \"\"\"\n",
    "    num_sequences = inputs_validation.shape[0]\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for i in range(num_sequences):\n",
    "            # Forward pass\n",
    "            input_seq = inputs_validation[i]\n",
    "            target = targets_validation[i]\n",
    "            # Reshape for batch compatibility\n",
    "            input_seq = input_seq.unsqueeze(0)  # Shape: [1, sequence_length, latent_size]\n",
    "            target = target.unsqueeze(0)        # Shape: [1, latent_size]\n",
    "            outputs = model(input_seq)\n",
    "            loss = criterion(outputs, target)\n",
    "            # Accumulate loss\n",
    "            val_loss += loss.item()\n",
    "    avg_loss = val_loss / num_sequences\n",
    "    return avg_loss\n",
    "\n",
    "def train_behavior_cloning(model, optimizer, criterion, inputs_training, targets_training, inputs_validation, targets_validation, num_epochs, writer = None):\n",
    "    \"\"\"Train a behavior cloning model of the LSTM class.\"\"\"\n",
    "    num_sequences = inputs_training.shape[0]\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "\n",
    "        # Loop over each sequence in the batch\n",
    "        training_loss = 0\n",
    "        for i in range(num_sequences):\n",
    "            # Prepare input and target\n",
    "            input_seq = inputs_training[i]\n",
    "            target = targets_training[i]\n",
    "\n",
    "            # Reshape for batch compatibility\n",
    "            input_seq = input_seq.unsqueeze(0)  # Shape: [1, sequence_length, latent_size]\n",
    "            target = target.unsqueeze(0)        # Shape: [1, latent_size]\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output, target)\n",
    "            training_loss += loss.item()\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_training_loss = training_loss / num_sequences\n",
    "        avg_validation_loss = validate_behavior_cloning(model, criterion, inputs_validation=inputs_validation, targets_validation=targets_validation)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar(\"TrainingLoss\", avg_training_loss, epoch)\n",
    "            writer.add_scalar(\"ValidationLoss\", avg_validation_loss, epoch)\n",
    "            writer.flush()\n",
    "\n",
    "\n",
    "        if (epoch+1) % 2 == 0: # was 0\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_training_loss:.4f} Validation Loss: {avg_validation_loss:.4f} ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the LSTMXYPredictor model \n",
    "\n",
    "Trains the single layer LSTM model LSTMXYPredictor. This is a baseline LSTM model. \n",
    "\n",
    "Training notes:\n",
    "* On the proprioception experiments, this reaches the performance:\n",
    "    Epoch [20/100], Training Loss: 0.0079 Validation Loss: 0.0080\n",
    "* No further improvement is observed from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'controller'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTMXYPredictor(latent_size\u001b[38;5;241m=\u001b[39mlatent_size, hidden_size\u001b[38;5;241m=\u001b[39mhidden_size, output_size \u001b[38;5;241m=\u001b[39m output_size, num_layers\u001b[38;5;241m=\u001b[39mnum_layers)\n\u001b[1;32m     10\u001b[0m task \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproprioception-uncluttered\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m inputs_training, targets_training, inputs_validation, targets_validation \u001b[38;5;241m=\u001b[39m create_bc_training_and_validation(task)\n\u001b[1;32m     14\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()  \u001b[38;5;66;03m# Mean Squared Error for regression\u001b[39;00m\n\u001b[1;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mcreate_bc_training_and_validation\u001b[0;34m(task)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_bc_training_and_validation\u001b[39m(task):\n\u001b[0;32m----> 2\u001b[0m     conv_vae_jsonfile \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(Config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontroller\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae_json\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m     conv_vae_model_pthfile \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(Config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontroller\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae_model\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m     sp \u001b[38;5;241m=\u001b[39m sp_conv_vae\u001b[38;5;241m.\u001b[39mConvVaeSensorProcessing(conv_vae_jsonfile,\n\u001b[1;32m      7\u001b[0m                                             conv_vae_model_pthfile)\n",
      "File \u001b[0;32m/lustre/fs1/home/ssheikholeslami/BerryPicker/src/behavior_cloning/../settings.py:48\u001b[0m, in \u001b[0;36mConfig.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'controller'"
     ]
    }
   ],
   "source": [
    "# Original\n",
    "latent_size = Config()[\"robot\"][\"latent_encoding_size\"]\n",
    "output_size = 6  # degrees of freedom in the robot\n",
    "num_layers = 2\n",
    "hidden_size = 32  #\n",
    "\n",
    "# Instantiate model, loss function, and optimizer\n",
    "model = LSTMXYPredictor(latent_size=latent_size, hidden_size=hidden_size, output_size = output_size, num_layers=num_layers)\n",
    "\n",
    "task = \"proprioception-uncluttered\"\n",
    "inputs_training, targets_training, inputs_validation, targets_validation = create_bc_training_and_validation(task)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 100\n",
    "\n",
    "# Create a SummaryWriter instance\n",
    "# where does the logdir go???\n",
    "writer = SummaryWriter(logdir=\"/home/lboloni/runs/example\")\n",
    "train_behavior_cloning(\n",
    "    model, optimizer, criterion,\n",
    "    inputs_training=inputs_training,\n",
    "    targets_training=targets_training,\n",
    "    inputs_validation=inputs_validation,\n",
    "    targets_validation=targets_validation,\n",
    "    num_epochs=num_epochs, writer=writer)\n",
    "print(\"Training complete.\")\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'controller'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# FIXME: save the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m filename_lstm \u001b[38;5;241m=\u001b[39m Config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontroller\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm_model_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), filename_lstm)\n",
      "File \u001b[0;32m/lustre/fs1/home/ssheikholeslami/BerryPicker/src/behavior_cloning/../settings.py:48\u001b[0m, in \u001b[0;36mConfig.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'controller'"
     ]
    }
   ],
   "source": [
    "\n",
    "# FIXME: save the model\n",
    "filename_lstm = Config()[\"controller\"][\"lstm_model_file\"]\n",
    "torch.save(model.state_dict(), filename_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the behavior cloning controller and use it with a real time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "latent_size = Config()[\"robot\"][\"latent_encoding_size\"]\n",
    "hidden_size = 32  # degrees of freedom in the robot\n",
    "output_size = 6  # degrees of freedom in the robot\n",
    "num_layers = 2\n",
    "\n",
    "# Instantiate model, loss function, and optimizer\n",
    "model = LSTMXYPredictor(latent_size=latent_size, hidden_size=hidden_size, output_size = output_size, num_layers=num_layers)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "filename_lstm = Config()[\"controller\"][\"lstm_model_file\"]\n",
    "model.load_state_dict(torch.load(filename_lstm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one demonstration\n",
    "task = \"proprioception-uncluttered\"\n",
    "sp = sp_conv_vae.ConvVaeSensorProcessing()\n",
    "\n",
    "demos_dir = pathlib.Path(Config()[\"demos\"][\"directory\"])\n",
    "task_dir = pathlib.Path(demos_dir, \"demos\", task)\n",
    "\n",
    "inputlist = []\n",
    "targetlist = []\n",
    "\n",
    "demo_dir = next(task_dir.iterdir())\n",
    "bcd = BCDemonstration(demo_dir, sensorprocessor=sp)\n",
    "z, a = bcd.read_z_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape[0]\n",
    "print(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(z.shape[0]-1):\n",
    "    input = torch.from_numpy(z[i])\n",
    "    input = input.unsqueeze(0)\n",
    "    input = input.unsqueeze(0)\n",
    "    print(input)\n",
    "    a_pred = model.forward_keep_state(input)\n",
    "    a_real = a[i+1]\n",
    "    print(f\"a_real: {a_real}\\na_pred: {a_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
